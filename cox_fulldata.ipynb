{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:32:03.735537Z",
     "start_time": "2024-04-25T15:32:03.695121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 读取数据C:\\MyProject\\MIMIC-IPE\\data\\base10.csv\n",
    "data = pd.read_csv('C:\\\\MyProject\\\\MIMIC-IPE\\\\data\\\\base10.csv')\n",
    "# 删除data中所有列名最后两位字符串为“_1”的列\n",
    "data = data.drop(data.columns[data.columns.str.endswith('_1')], axis=1)\n",
    "# 删除data中所有列名最后两位字符串为“_2”的列\n",
    "data = data.drop(data.columns[data.columns.str.endswith('_2')], axis=1)\n",
    "# 设置subject_id、hadm_id和stay_id为索引\n",
    "data = data.set_index(['subject_id'])"
   ],
   "id": "e72f9f8b076d00f5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:32:04.127543Z",
     "start_time": "2024-04-25T15:32:04.118579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "删除以下列：\n",
    "hadm_id\n",
    "stay_id\n",
    "blood_count_hematocrit\n",
    "blood_count_hemoglobin\n",
    "blood_count_mch\n",
    "blood_count_mchc\n",
    "blood_count_mcv\n",
    "blood_count_platelet\n",
    "blood_count_rbc\n",
    "blood_count_rdw\n",
    "blood_count_wbc\n",
    "coagulation_ptt\n",
    "'''\n",
    "data = data.drop(['hadm_id', 'stay_id', 'blood_count_hematocrit', 'blood_count_hemoglobin', 'blood_count_mch',\n",
    "                  'blood_count_mchc', 'blood_count_mcv', 'blood_count_platelet', 'blood_count_rbc',\n",
    "                  'blood_count_rdw', 'blood_count_wbc', 'coagulation_ptt'], axis=1)"
   ],
   "id": "6ffad5f14263f3d8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:32:04.630136Z",
     "start_time": "2024-04-25T15:32:04.617452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''删除以下列：\n",
    "hospstay_seq\n",
    "first_hosp_stay\n",
    "icustay_seq\n",
    "first_icu_stay\n",
    "icd_code\n",
    "icd_version\n",
    "\n",
    "dischtime\n",
    "icu_intime\n",
    "avg_los\n",
    "'''\n",
    "data = data.drop(['hospstay_seq', 'first_hosp_stay', 'icustay_seq', 'first_icu_stay', 'icd_code', 'icd_version',\n",
    "                  'dischtime', 'icu_intime', 'avg_los'], axis=1)\n",
    "'''提取以下几列，以下几列是待比较的值，形成一个新的dataframe：\n",
    "hospital_expire_flag\n",
    "re_inhosp\n",
    "icu_count\n",
    "14-days\n",
    "31-days\n",
    "los_icu\n",
    "'''\n",
    "data_compare = data[['hospital_expire_flag', 're_inhosp', 'icu_count', '14-days', '31-days', 'los_icu']]\n",
    "# 从data中删除以上列\n",
    "data = data.drop(['hospital_expire_flag', 're_inhosp', 'icu_count', '14-days', '31-days', 'los_icu'], axis=1)"
   ],
   "id": "3ad9289d5f96ce04",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:32:05.252746Z",
     "start_time": "2024-04-25T15:32:05.234555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data中的gender列使用labelencoder进行编码\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Fit and transform the 'gender' column in 'X'\n",
    "data['gender'] = labelencoder.fit_transform(data['gender'])\n",
    "# data中的Group_label列使用labelencoder进行编码\n",
    "# Fit and transform the 'Group_label' column in 'X'\n",
    "data['Group_Label'] = labelencoder.fit_transform(data['Group_Label'])\n",
    "# Decode the encoded 'Group_Label' column and print the results\n",
    "decoded_labels = labelencoder.inverse_transform(data['Group_Label'])\n",
    "encoded_labels = data['Group_Label'].unique()\n",
    "# 使用 inverse_transform 方法将数字编码还原为原始标签\n",
    "original_labels = labelencoder.inverse_transform(encoded_labels)\n",
    "# 打印出数字编码及其对应的原始标签\n",
    "for encoded, original in zip(encoded_labels, original_labels):\n",
    "    print(f'{encoded}: {original}')\n",
    "# X中的race列使用one-hot编码，然后再将原race列删除，再把one-hot编码后的列加入X\n",
    "# Perform one-hot encoding on the 'race' column\n",
    "race_dummies = pd.get_dummies(data['race'], prefix='race')\n",
    "# Drop the original 'race' column from 'data'\n",
    "data = data.drop('race', axis=1)\n",
    "# Concatenate 'data' with the one-hot encoded DataFrame\n",
    "data = pd.concat([data, race_dummies], axis=1)"
   ],
   "id": "3d345bf46272f76c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: DVT-PE\n",
      "1: IPE\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:17:03.071926Z",
     "start_time": "2024-04-25T15:17:03.052622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 转换日期格式为日期时间格式\n",
    "data['dod'] = pd.to_datetime(data['dod'])\n",
    "data['admittime'] = pd.to_datetime(data['admittime'])\n",
    "\n",
    "# 计算事件发生或观察结束的天数\n",
    "data['obs_days'] = (data['dod'] - data['admittime']).dt.days\n",
    "\n",
    "# 创建事件状态列，1表示在观察期间内发生了感兴趣的事件，0表示没有或数据被删失\n",
    "data['event_status'] = np.where(data['dod'].notnull(), 1, 0)\n",
    "\n",
    "# 删除不再需要的列\n",
    "data = data.drop('admittime', axis=1)\n",
    "\n"
   ],
   "id": "805fddbf31866f90",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:17:06.234169Z",
     "start_time": "2024-04-25T15:17:06.224345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_# 获取data中的所有列名、列中空值计数和列中空值占比，形成一个新的DataFrame\n",
    "data_info = pd.DataFrame(data.columns, columns=['column_name'])\n",
    "data_info['missing_count'] = data.isnull().sum().values\n",
    "# 将空值占比转换为百分数形式\n",
    "data_info['missing_rate'] = (data.isnull().sum().values / data.shape[0] * 100).round(2)"
   ],
   "id": "e1194e1a075a9b9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T15:17:06.762117Z",
     "start_time": "2024-04-25T15:17:06.638842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将data保存到C:\\MyProject\\MIMIC-IPE\\data\\full_dataforcox.csv\n",
    "data.to_csv('C:/MyProject/MIMIC-IPE/data/full_dataforcox.csv')"
   ],
   "id": "fc3f6d72d5356dc4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T07:45:45.701865Z",
     "start_time": "2024-04-24T07:45:45.338334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# data中event_status列为事件列，death_day列为时间列，其余列为特征列，Group_Label为分组列，对data进行Kaplan-Meier生存曲线分析，使用log-rank检验，并且画出生存曲线\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# 初始化KaplanMeierFitter类\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# 对每个组进行Kaplan-Meier生存曲线分析，并画出生存曲线\n",
    "groups = data['Group_Label'].unique()\n",
    "for i, group in enumerate(groups):\n",
    "    group_data = data[data['Group_Label'] == group]\n",
    "    kmf.fit(group_data['death_time'], group_data['7-days'], label=str(group))\n",
    "    kmf.plot()\n",
    "\n",
    "# 对每两个组进行log-rank检验\n",
    "for i in range(len(groups)):\n",
    "    for j in range(i+1, len(groups)):\n",
    "        group_i_data = data[data['Group_Label'] == groups[i]]\n",
    "        group_j_data = data[data['Group_Label'] == groups[j]]\n",
    "        results = logrank_test(group_i_data['death_time'], group_j_data['death_time'],\n",
    "                               event_observed_A=group_i_data['7-days'], event_observed_B=group_j_data['7-days'])\n",
    "        print(f'Log-rank test between group {groups[i]} and group {groups[j]}: p={results.p_value}')"
   ],
   "id": "929b80b770cea44d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NaNs were detected in the dataset. Try using pd.isnull to find the problematic values.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(groups):\n\u001B[0;32m     11\u001B[0m     group_data \u001B[38;5;241m=\u001B[39m data[data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGroup_Label\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m group]\n\u001B[1;32m---> 12\u001B[0m     kmf\u001B[38;5;241m.\u001B[39mfit(group_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdeath_day\u001B[39m\u001B[38;5;124m'\u001B[39m], group_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevent_status\u001B[39m\u001B[38;5;124m'\u001B[39m], label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(group))\n\u001B[0;32m     13\u001B[0m     kmf\u001B[38;5;241m.\u001B[39mplot()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Perform log-rank test between each pair of groups\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NN\\Lib\\site-packages\\lifelines\\utils\\__init__.py:56\u001B[0m, in \u001B[0;36mCensoringType.right_censoring.<locals>.f\u001B[1;34m(model, *args, **kwargs)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(function)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mf\u001B[39m(model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mset_censoring_type(model, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mRIGHT)\n\u001B[1;32m---> 56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m function(model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NN\\Lib\\site-packages\\lifelines\\fitters\\kaplan_meier_fitter.py:127\u001B[0m, in \u001B[0;36mKaplanMeierFitter.fit\u001B[1;34m(self, durations, event_observed, timeline, entry, label, alpha, ci_labels, weights, fit_options)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;129m@CensoringType\u001B[39m\u001B[38;5;241m.\u001B[39mright_censoring\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     91\u001B[0m     fit_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     92\u001B[0m ):  \u001B[38;5;66;03m# pylint: disable=too-many-arguments,too-many-locals\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;124;03m    Fit the model to a right-censored dataset\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    124\u001B[0m \n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit(durations, event_observed, timeline, entry, label, alpha, ci_labels, weights)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NN\\Lib\\site-packages\\lifelines\\fitters\\kaplan_meier_fitter.py:327\u001B[0m, in \u001B[0;36mKaplanMeierFitter._fit\u001B[1;34m(self, durations, event_observed, timeline, entry, label, alpha, ci_labels, weights)\u001B[0m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m    299\u001B[0m \u001B[38;5;124;03m----------\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    324\u001B[0m \n\u001B[0;32m    325\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    326\u001B[0m durations \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(durations)\n\u001B[1;32m--> 327\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_values(durations)\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event_observed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    330\u001B[0m     event_observed \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(event_observed)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NN\\Lib\\site-packages\\lifelines\\fitters\\kaplan_meier_fitter.py:409\u001B[0m, in \u001B[0;36mKaplanMeierFitter._check_values\u001B[1;34m(self, array)\u001B[0m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_values\u001B[39m(\u001B[38;5;28mself\u001B[39m, array):\n\u001B[1;32m--> 409\u001B[0m     check_nans_or_infs(array)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\NN\\Lib\\site-packages\\lifelines\\utils\\__init__.py:1176\u001B[0m, in \u001B[0;36mcheck_nans_or_infs\u001B[1;34m(df_or_array)\u001B[0m\n\u001B[0;32m   1173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m check_nans_or_infs(df_or_array\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pd\u001B[38;5;241m.\u001B[39misnull(df_or_array)\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m-> 1176\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNaNs were detected in the dataset. Try using pd.isnull to find the problematic values.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1178\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1179\u001B[0m     infs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39misinf(df_or_array)\n",
      "\u001B[1;31mTypeError\u001B[0m: NaNs were detected in the dataset. Try using pd.isnull to find the problematic values."
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d80b394441ccc8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
