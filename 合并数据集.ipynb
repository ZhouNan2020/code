{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T07:04:04.496378Z",
     "start_time": "2024-05-10T07:04:02.573163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\base10.csv\n",
    "data = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\base10.csv')\n",
    "# 查看data的列名，存入一个dataframe\n",
    "columns = pd.DataFrame(data.columns)\n",
    "# List of columns to keep\n",
    "columns_to_keep = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"icd_code\",\n",
    "    \"icd_version\",\n",
    "    \"Group_Label\",\n",
    "    \"admittime\",\n",
    "    \"dischtime\",\n",
    "    \"deathtime\",\n",
    "    \"hospital_expire_flag\",\n",
    "    \"dod\",\n",
    "    \"death_time_days\",\n",
    "    \"re_inhosp\",\n",
    "    \"icu_count\",\n",
    "    \"avg_los\",\n",
    "    \"death_days\",\n",
    "    \"7-days\",\n",
    "    \"14-days\",\n",
    "    \"31-days\",\n",
    "    \"stay_id\",\n",
    "    \"icu_intime\",\n",
    "    \"gender\",\n",
    "    \"hospstay_seq\",\n",
    "    \"first_hosp_stay\",\n",
    "    \"icustay_seq\",\n",
    "    \"first_icu_stay\",\n",
    "    \"los_icu\",\n",
    "    \"weight_admit\",\n",
    "    \"height\",\n",
    "    \"first_hosp\",\n",
    "    \n",
    "    \"race\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "data = data[columns_to_keep]\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\data\\anti_combine.csv\n",
    "anti = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\data\\anti_combine.csv')\n",
    "# 查看anti的列名，存入一个dataframe\n",
    "columns_anti = pd.DataFrame(anti.columns)\n",
    "'''\n",
    "anti仅保留以下列：\n",
    "subject_id\n",
    "hadm_id\n",
    "tumor_disease\n",
    "Blood-related diseases\n",
    "Cardiovascular and metabolic diseases\n",
    "No Blood-related disease\n",
    "Other Coagulation Defects\n",
    "Primary Thrombocytopenia\n",
    "Thrombotic Thrombocytopenic Purpura\n",
    "Atrial fibrillation\n",
    "CAD\n",
    "Diabetes\n",
    "Heart failure\n",
    "Hypertension\n",
    "No Cardiovascular and metabolic diseases\n",
    "PAD\n",
    "Lung_Tumor\n",
    "No tumor disease\n",
    "Non_Solid_Tumor\n",
    "Other_Solid_Tumor\n",
    "\n",
    "'''\n",
    "# List of columns to keep in the 'anti' dataframe\n",
    "columns_to_keep_anti = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"tumor_disease\",\n",
    "    \"Blood-related diseases\",\n",
    "    \"Cardiovascular and metabolic diseases\",\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "anti = anti[columns_to_keep_anti]\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\full_dataforcox.csv\n",
    "cox = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\full_dataforcox.csv')\n",
    "# 查看cox的列名，存入一个dataframe\n",
    "columns_cox = pd.DataFrame(cox.columns)\n",
    "'''\n",
    "cox仅保留以下列：\n",
    "subject_id\n",
    "obs_days\n",
    "event_status\n",
    "\"race_AMERICAN INDIAN/ALASKA NATIVE\",\n",
    "    \"race_ASIAN\",\n",
    "    \"race_ASIAN - CHINESE\",\n",
    "    \"race_BLACK/AFRICAN\",\n",
    "    \"race_BLACK/AFRICAN AMERICAN\",\n",
    "    \"race_BLACK/CAPE VERDEAN\",\n",
    "    \"race_BLACK/CARIBBEAN ISLAND\",\n",
    "    \"race_HISPANIC OR LATINO\",\n",
    "    \"race_HISPANIC/LATINO - COLUMBIAN\",\n",
    "    \"race_HISPANIC/LATINO - DOMINICAN\",\n",
    "    \"race_HISPANIC/LATINO - GUATEMALAN\",\n",
    "    \"race_HISPANIC/LATINO - PUERTO RICAN\",\n",
    "    \"race_MULTIPLE RACE/ETHNICITY\",\n",
    "    \"race_OTHER\",\n",
    "    \"race_PATIENT DECLINED TO ANSWER\",\n",
    "    \"race_PORTUGUESE\",\n",
    "    \"race_SOUTH AMERICAN\",\n",
    "    \"race_UNABLE TO OBTAIN\",\n",
    "    \"race_UNKNOWN\",\n",
    "    \"race_WHITE\",\n",
    "    \"race_WHITE - EASTERN EUROPEAN\",\n",
    "    \"race_WHITE - OTHER EUROPEAN\",\n",
    "    \"race_WHITE - RUSSIAN\",\n",
    "'''\n",
    "# List of columns to keep in the 'cox' dataframe\n",
    "columns_to_keep_cox = [\n",
    "    \"subject_id\",\n",
    "    \"obs_days\",\n",
    "    \"event_status\",\n",
    "    \"race_AMERICAN INDIAN/ALASKA NATIVE\",\n",
    "    \"race_ASIAN\",\n",
    "    \"race_ASIAN - CHINESE\",\n",
    "    \"race_BLACK/AFRICAN\",\n",
    "    \"race_BLACK/AFRICAN AMERICAN\",\n",
    "    \"race_BLACK/CAPE VERDEAN\",\n",
    "    \"race_BLACK/CARIBBEAN ISLAND\",\n",
    "    \"race_HISPANIC OR LATINO\",\n",
    "    \"race_HISPANIC/LATINO - COLUMBIAN\",\n",
    "    \"race_HISPANIC/LATINO - DOMINICAN\",\n",
    "    \"race_HISPANIC/LATINO - GUATEMALAN\",\n",
    "    \"race_HISPANIC/LATINO - PUERTO RICAN\",\n",
    "    \"race_MULTIPLE RACE/ETHNICITY\",\n",
    "    \"race_OTHER\",\n",
    "    \"race_PATIENT DECLINED TO ANSWER\",\n",
    "    \"race_PORTUGUESE\",\n",
    "    \"race_SOUTH AMERICAN\",\n",
    "    \"race_UNABLE TO OBTAIN\",\n",
    "    \"race_UNKNOWN\",\n",
    "    \"race_WHITE\",\n",
    "    \"race_WHITE - EASTERN EUROPEAN\",\n",
    "    \"race_WHITE - OTHER EUROPEAN\",\n",
    "    \"race_WHITE - RUSSIAN\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "cox = cox[columns_to_keep_cox]\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\合并抗凝用药.csv\n",
    "med = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\合并抗凝用药.csv')\n",
    "# 查看med的列名，存入一个dataframe\n",
    "columns_med = pd.DataFrame(med.columns)\n",
    "'''\n",
    "med仅保留以下列：\n",
    "subject_id\n",
    "hadm_id\n",
    "Direct thrombin inhibitor\n",
    "Factor Xa inhibitor\n",
    "Unfractionated heparin\n",
    "Vitamin K antagonist\n",
    "\n",
    "'''\n",
    "# List of columns to keep in the 'med' dataframe\n",
    "columns_to_keep_med = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"Direct thrombin inhibitor\",\n",
    "    \"Factor Xa inhibitor\",\n",
    "    \"Unfractionated heparin\",\n",
    "    \"Vitamin K antagonist\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "med = med[columns_to_keep_med]\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\住院时间与ICU时间.csv\n",
    "time = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\住院时间与ICU时间.csv')\n",
    "# 查看time的列名，存入一个dataframe\n",
    "columns_time = pd.DataFrame(time.columns)\n",
    "'''\n",
    "time仅保留以下列：\n",
    "subject_id\n",
    "hadm_id\n",
    "hosp_time_hour\n",
    "icu_count\n",
    "icu_total_los_day\n",
    "icu_total_hour\n",
    "'''\n",
    "# List of columns to keep in the 'time' dataframe\n",
    "columns_to_keep_time = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"hosp_time_hour\",\n",
    "    \"icu_count\",\n",
    "    \"icu_total_los_day\",\n",
    "    \"icu_total_hour\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "time = time[columns_to_keep_time]\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\再入院情况表.csv\n",
    "rehosp = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\再入院情况表.csv')\n",
    "# 查看rehosp的列名，存入一个dataframe\n",
    "columns_rehosp = pd.DataFrame(rehosp.columns)\n",
    "'''\n",
    "rehosp仅保留以下列：\n",
    "subject_id\n",
    "hadm_id\n",
    "Group_Label\n",
    "re_inhosp\n",
    "re_inhosp_time\n",
    "next_admission_type\n",
    "\n",
    "'''\n",
    "# List of columns to keep in the 'rehosp' dataframe\n",
    "columns_to_keep_rehosp = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"re_inhosp\",\n",
    "    \"re_inhosp_time\",\n",
    "    \"next_admission_type\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "rehosp = rehosp[columns_to_keep_rehosp]\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\死在哪一次住院.csv\n",
    "death = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\死在哪一次住院.csv')\n",
    "# 查看death的列名，存入一个dataframe\n",
    "columns_death = pd.DataFrame(death.columns)\n",
    "'''\n",
    "death仅保留以下列：\n",
    "subject_id\n",
    "hadm_id\n",
    "death_in1st_hadm\n",
    "death_by_PE\n",
    "seq_num\n",
    "hospital_expire_flag\n",
    "'''\n",
    "\n",
    "# List of columns to keep in the 'death' dataframe\n",
    "columns_to_keep_death = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"death_in1st_hadm\",\n",
    "    \"death_by_PE\",\n",
    "    \"seq_num\",\n",
    "    \"hospital_expire_flag\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "death = death[columns_to_keep_death]\n",
    "\n",
    "# 查看death的subject_id列和hadm_id列是否有重复值，如果有，将重复值存入一个列表\n",
    "# Check for duplicate values in 'subject_id' and 'hadm_id' columns\n",
    "duplicates = death[death.duplicated(subset=['subject_id', 'hadm_id'], keep=False)]\n",
    "duplicates\n",
    "\n",
    "# 从death中删除id包含在duplicate中，且death_in1st_hadm列的值为0的行\n",
    "death = death[~((death['subject_id'].isin(duplicates['subject_id'])) & (death['hadm_id'].isin(duplicates['hadm_id'])) & (death['death_in1st_hadm'] == 0))]\n",
    "\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\下一次PE入院情况表.csv\n",
    "next_pe = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\下一次PE入院情况表.csv')\n",
    "# 查看next_pe的列名，存入一个dataframe\n",
    "columns_next_pe = pd.DataFrame(next_pe.columns)\n",
    "'''\n",
    "next_pe仅保留以下列：\n",
    "subject_id\n",
    "hadm_id\n",
    "seq_hosp\n",
    "next_PE\n",
    "next_PE_day\n",
    "\n",
    "'''\n",
    "# List of columns to keep in the 'next_pe' dataframe\n",
    "columns_to_keep_next_pe = [\n",
    "    \"subject_id\",\n",
    "    \"hadm_id\",\n",
    "    \"seq_hosp\",\n",
    "    \"next_PE\",\n",
    "    \"next_PE_day\"\n",
    "]\n",
    "\n",
    "# Keep only the columns in the list\n",
    "next_pe = next_pe[columns_to_keep_next_pe]\n",
    "# 合并data、anti、cox、med、time、rehosp、death、next_pe，使用subject_id和hadm_id作为合并键。注意，有些数据集可能没有hadm_id，如果没有，只使用subject_id作为合并键。最终数据集的行数应该等于data的行数。如果有重复的列名，可以在列名后加上'_{所来自的数据集名称}'作为后缀，如'subject_id_anti'。\n",
    "# 定义合并函数\n",
    "def merge_datasets(base, new, suffix):\n",
    "    # 检查 'hadm_id' 是否在新数据集中\n",
    "    if 'hadm_id' in new.columns:\n",
    "        # 使用 'subject_id' 和 'hadm_id' 合并\n",
    "        merged = pd.merge(base, new, on=['subject_id', 'hadm_id'], how='left', suffixes=('', f'_{suffix}'))\n",
    "    else:\n",
    "        # 只使用 'subject_id' 合并\n",
    "        merged = pd.merge(base, new, on='subject_id', how='left', suffixes=('', f'_{suffix}'))\n",
    "\n",
    "    # 处理重复列名（自动添加的后缀处理了大部分情况，这里可以额外处理其它需要特殊处理的情况）\n",
    "    # 示例：处理特殊重复列\n",
    "    # if 'some_column' in merged.columns:\n",
    "    #     merged.rename(columns={'some_column': f'some_column_{suffix}'}, inplace=True)\n",
    "\n",
    "    return merged\n",
    "\n",
    "# 开始逐一合并数据集\n",
    "datasets = [anti, cox, med, time, rehosp, death, next_pe]\n",
    "dataset_names = ['anti', 'cox', 'med', 'time', 'rehosp', 'death', 'next_pe']\n",
    "\n",
    "# 初始化最终的数据集为 'data'\n",
    "final_data = data\n",
    "\n",
    "# 循环合并其它数据集\n",
    "for dataset, name in zip(datasets, dataset_names):\n",
    "    final_data = merge_datasets(final_data, dataset, name)\n",
    "\n",
    "# 输出最终的数据集结构\n",
    "print(final_data.info())\n",
    "\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\data\\新分组.csv\n",
    "group = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\data\\新分组.csv')\n",
    "# group只保留subject_id,hadm_id,Group_Label列，并且Group_Label列改名为new_group_label\n",
    "group = group[['subject_id', 'hadm_id', 'Group_Label']]\n",
    "group.rename(columns={'Group_Label': 'new_group_label'}, inplace=True)\n",
    "# 合并到final_data中，使用subject_id和hadm_id作为合并键\n",
    "final_data = pd.merge(final_data, group, on=['subject_id', 'hadm_id'], how='left')\n",
    "\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\data\\年龄.csv\n",
    "age = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\data\\年龄.csv')\n",
    "# 合并到final_data中，使用subject_id和hadm_id作为合并键\n",
    "final_data = pd.merge(final_data, age, on=['subject_id', 'hadm_id'], how='left')\n",
    "import numpy as np\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\data\\到底死在哪一次住院.csv\n",
    "death_hadm = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\data\\到底死在哪一次住院.csv')\n",
    "# 计算death_due_toPE和death_in1st_hosp列的非0值的个数，print出来\n",
    "print(death_hadm['death_due_toPE'].value_counts())\n",
    "print(death_hadm['death_in1st_hosp'].value_counts())\n",
    "\n",
    "\n",
    "# Convert 'deathtime', 'dischtime', 'admittime' to datetime in hours\n",
    "death_hadm['deathtime'] = pd.to_datetime(death_hadm['deathtime'])\n",
    "death_hadm['dischtime'] = pd.to_datetime(death_hadm['dischtime'])\n",
    "death_hadm['admittime'] = pd.to_datetime(death_hadm['admittime'])\n",
    "\n",
    "# Create a dictionary to store the first admission time for each subject_id\n",
    "first_admit_times = death_hadm.groupby('subject_id')['admittime'].min().to_dict()\n",
    "\n",
    "# Define a function to calculate the difference in hours\n",
    "def calculate_hours(row):\n",
    "    if row['death_due_toPE'] == 1 and row['deathtime'] <= row['dischtime']:\n",
    "        first_admit_time = first_admit_times[row['subject_id']]\n",
    "        return (row['deathtime'] - first_admit_time).total_seconds() / 3600\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create the new 'death_due_toPE_days' column\n",
    "death_hadm['death_due_toPE_days'] = death_hadm.apply(calculate_hours, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# 合并death_hadm中subject_id相同的行，保留death_due_toPE列或death_in1st_hosp列任意一列有非0值的行\n",
    "# Group by 'subject_id' and check for non-zero values in 'death_due_toPE' or 'death_in1st_hosp'\n",
    "death_hadm_1 = death_hadm.groupby('subject_id').apply(lambda group: group[(group['death_due_toPE'] != 0) | (group['death_in1st_hosp'] != 0)])\n",
    "# Reset the index\n",
    "death_hadm_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('处理后',death_hadm_1['death_due_toPE'].value_counts())\n",
    "print('处理后',death_hadm_1['death_in1st_hosp'].value_counts())\n",
    "# 将death_hadm_1合并到final_data中，使用subject_id作为合并键，只保留death_hadm_1的death_due_toPE和death_in1st_hosp列，death_due_toPE_days列\n",
    "final_data = pd.merge(final_data, death_hadm_1[['subject_id', 'death_due_toPE', 'death_in1st_hosp', 'death_due_toPE_days']], on='subject_id', how='left')\n",
    "# death_due_toPE和death_in1st_hosp列的缺失值填充为0\n",
    "final_data['death_due_toPE'].fillna(0, inplace=True)\n",
    "final_data['death_in1st_hosp'].fillna(0, inplace=True)\n",
    "# 读取C:\\MyProject\\MIMIC-IPE\\data\\住ICU的天数和小时数.csv\n",
    "icu = pd.read_csv(r'C:\\MyProject\\MIMIC-IPE\\data\\住ICU的天数和小时数.csv')\n",
    "# print出icu的subject_id列和hadm_id列有多少个不同的值\n",
    "print(icu['subject_id'].nunique())\n",
    "print(icu['hadm_id'].nunique())\n",
    "# icu增加一个列，icu_count_num,计算同一个subject_id且同一个hadm_id下对应的不同stay_id的行计数，将值填入icu_count_num中。\n",
    "# Ensure 'stay_id' is in string format for counting unique values\n",
    "icu['stay_id'] = icu['stay_id'].astype(str)\n",
    "# Create 'icu_count_num' column\n",
    "icu['icu_count_num'] = icu.groupby(['subject_id', 'hadm_id'])['stay_id'].transform('nunique')\n",
    "\n",
    "# icu只保留subject_id,hadm_id,icu_count_num，los_icu列\n",
    "icu = icu[['subject_id', 'hadm_id', 'stay_id','icu_count_num', 'los_icu']]\n",
    "# 将同一个subject_id并且同一个hadm_id下对应的不同stay_id的行合并，将los_icu列的值相加，填入los_icu列中\n",
    "icu = icu.groupby(['subject_id', 'hadm_id', 'icu_count_num']).agg({'los_icu': 'sum'}).reset_index()\n",
    "# 增加一列，icu_total_los_hour，计算icu_total_los_day列的小时数，填入icu_total_los_hour中\n",
    "icu['icu_total_los_hour'] = icu['los_icu'] * 24\n",
    "# 将icu合并到final_data中，使用subject_id和hadm_id作为合并键\n",
    "final_data = pd.merge(final_data, icu, on=['subject_id', 'hadm_id'], how='left')\n",
    "\n",
    "\n",
    "# 查看final_data的列名，存入一个dataframe\n",
    "columns_final_data = pd.DataFrame(final_data.columns)\n",
    "'''更改final_data的以下列名：\n",
    "event_status -> Death event\n",
    "obs_days -> Time of death (days)\n",
    "7-days -> Deaths within 7 days\n",
    "14-days -> Deaths within 14 days\n",
    "31-days -> Deaths within 31 days\n",
    "icu_count -> Count of ICU stays\n",
    "icu_total_los_hour -> Total ICU stay (hours)\n",
    "first_hosp -> First hospitalization\n",
    "hosp_time_hour -> Length of hospital stay (hours)\n",
    "re_inhosp_rehosp -> NRPE\n",
    "next_PE -> UNRPE\n",
    "re_inhosp_time -> NRPE event time span\n",
    "next_PE_day -> UNRPE event time span\n",
    "death_in1st_hosp -> Death due to first admission for PE\n",
    "death_due_toPE -> Death due to PE\n",
    "death_due_toPE_days -> Death due to PE event time span\n",
    "'''\n",
    "final_data.rename(columns={\n",
    "    'event_status': 'Death event',\n",
    "    'obs_days': 'Time of death (days)',\n",
    "    '7-days': 'Deaths within 7 days',\n",
    "    '14-days': 'Deaths within 14 days',\n",
    "    '31-days': 'Deaths within 31 days',\n",
    "    'icu_count': 'Count of ICU stays',\n",
    "    'icu_total_los_hour': 'Total ICU stay (hours)',\n",
    "    'first_hosp': 'First hospitalization',\n",
    "    'hosp_time_hour': 'Length of hospital stay (hours)',\n",
    "    're_inhosp': 'NRPE',\n",
    "    'next_PE': 'UNRPE',\n",
    "    're_inhosp_time': 'NRPE event time span',\n",
    "    'next_PE_day': 'UNRPE event time span',\n",
    "    'death_in1st_hosp': 'Death due to first admission for PE',\n",
    "    'death_due_toPE': 'Death due to PE',\n",
    "    'death_due_toPE_days': 'Death due to PE event time span'\n",
    "}, inplace=True)\n",
    "\n",
    "# 查看final_data的列名，存入一个dataframe\n",
    "columns_final_data = pd.DataFrame(final_data.columns)\n",
    "'''\n",
    "删除以下列：\n",
    "icd_code\n",
    "icd_version\n",
    "\n",
    "icu_intime\n",
    "\n",
    "first_hosp_stay\n",
    "icustay_seq\n",
    "first_icu_stay\n",
    "los_icu_x\n",
    "death_in1st_hadm\n",
    "death_by_PE\n",
    "hospital_expire_flag_death\n",
    "\n",
    "los_icu_y\n",
    "'''\n",
    "# Drop the columns\n",
    "final_data.drop(columns=[\n",
    "    'icd_code',\n",
    "    'icd_version',\n",
    "\n",
    "    'icu_intime',\n",
    "\n",
    "    'first_hosp_stay',\n",
    "    'icustay_seq',\n",
    "    'first_icu_stay',\n",
    "    'los_icu_x',\n",
    "    'death_in1st_hadm',\n",
    "    'death_by_PE',\n",
    "    'hospital_expire_flag_death',\n",
    "\n",
    "    'los_icu_y'\n",
    "], inplace=True)\n",
    "# 查看final_data中race列的unique值，存入一个datafrmae\n",
    "# Get unique values from 'race' column\n",
    "unique_races = final_data['race'].unique()\n",
    "\n",
    "# Convert the array of unique values to a DataFrame\n",
    "unique_races_df = pd.DataFrame(unique_races, columns=['race'])\n",
    "# 定义民族映射字典\n",
    "race_mapping = {\n",
    "    'WHITE': 'White',\n",
    "    'WHITE - OTHER EUROPEAN': 'White',\n",
    "    'WHITE - RUSSIAN': 'White',\n",
    "    'WHITE - EASTERN EUROPEAN': 'White',\n",
    "    'PORTUGUESE': 'White',\n",
    "    'BLACK/AFRICAN AMERICAN': 'Black or African American',\n",
    "    'BLACK/AFRICAN': 'Black or African American',\n",
    "    'BLACK/CARIBBEAN ISLAND': 'Black or African American',\n",
    "    'BLACK/CAPE VERDEAN': 'Black or African American',\n",
    "    'HISPANIC/LATINO - DOMINICAN': 'Hispanic or Latino',\n",
    "    'HISPANIC/LATINO - GUATEMALAN': 'Hispanic or Latino',\n",
    "    'HISPANIC OR LATINO': 'Hispanic or Latino',\n",
    "    'HISPANIC/LATINO - PUERTO RICAN': 'Hispanic or Latino',\n",
    "    'HISPANIC/LATINO - COLUMBIAN': 'Hispanic or Latino',\n",
    "    'ASIAN': 'Asian',\n",
    "    'ASIAN - CHINESE': 'Asian',\n",
    "    'OTHER': 'Other',\n",
    "    'MULTIPLE RACE/ETHNICITY': 'Other',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE': 'Other',\n",
    "    'SOUTH AMERICAN': 'Other',\n",
    "    'UNKNOWN': 'Unknown or Declined',\n",
    "    'PATIENT DECLINED TO ANSWER': 'Unknown or Declined',\n",
    "    'UNABLE TO OBTAIN': 'Unknown or Declined',\n",
    "    'NaN': 'Unknown or Declined',\n",
    "    np.nan: 'Unknown or Declined',\n",
    "    'nan': 'Unknown or Declined'\n",
    "}\n",
    "\n",
    "# 应用映射\n",
    "final_data['race'] = final_data['race'].map(race_mapping)\n",
    "# Now 'unique_races_df' is a DataFrame containing the unique values from the 'race' column\n",
    "# 保存最终的数据集到C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\用于统计的完整数据集.csv\n",
    "final_data.to_csv(r'C:\\MyProject\\MIMIC-IPE\\加了中介变量的数据集\\备用数据集.csv', index=False)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2039 entries, 0 to 2038\n",
      "Data columns (total 76 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   subject_id                             2039 non-null   int64  \n",
      " 1   hadm_id                                2039 non-null   int64  \n",
      " 2   icd_code                               2039 non-null   object \n",
      " 3   icd_version                            2039 non-null   int64  \n",
      " 4   Group_Label                            2039 non-null   object \n",
      " 5   admittime                              2039 non-null   object \n",
      " 6   dischtime                              2039 non-null   object \n",
      " 7   deathtime                              66 non-null     object \n",
      " 8   hospital_expire_flag                   2039 non-null   int64  \n",
      " 9   dod                                    593 non-null    object \n",
      " 10  death_time_days                        593 non-null    float64\n",
      " 11  re_inhosp                              2039 non-null   int64  \n",
      " 12  icu_count                              2039 non-null   int64  \n",
      " 13  avg_los                                2039 non-null   float64\n",
      " 14  death_days                             593 non-null    float64\n",
      " 15  7-days                                 2039 non-null   int64  \n",
      " 16  14-days                                2039 non-null   int64  \n",
      " 17  31-days                                2039 non-null   int64  \n",
      " 18  stay_id                                588 non-null    float64\n",
      " 19  icu_intime                             588 non-null    object \n",
      " 20  gender                                 588 non-null    object \n",
      " 21  hospstay_seq                           588 non-null    float64\n",
      " 22  first_hosp_stay                        588 non-null    object \n",
      " 23  icustay_seq                            588 non-null    float64\n",
      " 24  first_icu_stay                         588 non-null    object \n",
      " 25  los_icu                                588 non-null    float64\n",
      " 26  weight_admit                           572 non-null    float64\n",
      " 27  height                                 239 non-null    float64\n",
      " 28  first_hosp                             2039 non-null   int64  \n",
      " 29  race                                   588 non-null    object \n",
      " 30  tumor_disease                          2039 non-null   object \n",
      " 31  Blood-related diseases                 2039 non-null   object \n",
      " 32  Cardiovascular and metabolic diseases  2039 non-null   object \n",
      " 33  obs_days                               593 non-null    float64\n",
      " 34  event_status                           2039 non-null   int64  \n",
      " 35  race_AMERICAN INDIAN/ALASKA NATIVE     2039 non-null   bool   \n",
      " 36  race_ASIAN                             2039 non-null   bool   \n",
      " 37  race_ASIAN - CHINESE                   2039 non-null   bool   \n",
      " 38  race_BLACK/AFRICAN                     2039 non-null   bool   \n",
      " 39  race_BLACK/AFRICAN AMERICAN            2039 non-null   bool   \n",
      " 40  race_BLACK/CAPE VERDEAN                2039 non-null   bool   \n",
      " 41  race_BLACK/CARIBBEAN ISLAND            2039 non-null   bool   \n",
      " 42  race_HISPANIC OR LATINO                2039 non-null   bool   \n",
      " 43  race_HISPANIC/LATINO - COLUMBIAN       2039 non-null   bool   \n",
      " 44  race_HISPANIC/LATINO - DOMINICAN       2039 non-null   bool   \n",
      " 45  race_HISPANIC/LATINO - GUATEMALAN      2039 non-null   bool   \n",
      " 46  race_HISPANIC/LATINO - PUERTO RICAN    2039 non-null   bool   \n",
      " 47  race_MULTIPLE RACE/ETHNICITY           2039 non-null   bool   \n",
      " 48  race_OTHER                             2039 non-null   bool   \n",
      " 49  race_PATIENT DECLINED TO ANSWER        2039 non-null   bool   \n",
      " 50  race_PORTUGUESE                        2039 non-null   bool   \n",
      " 51  race_SOUTH AMERICAN                    2039 non-null   bool   \n",
      " 52  race_UNABLE TO OBTAIN                  2039 non-null   bool   \n",
      " 53  race_UNKNOWN                           2039 non-null   bool   \n",
      " 54  race_WHITE                             2039 non-null   bool   \n",
      " 55  race_WHITE - EASTERN EUROPEAN          2039 non-null   bool   \n",
      " 56  race_WHITE - OTHER EUROPEAN            2039 non-null   bool   \n",
      " 57  race_WHITE - RUSSIAN                   2039 non-null   bool   \n",
      " 58  Direct thrombin inhibitor              943 non-null    float64\n",
      " 59  Factor Xa inhibitor                    943 non-null    float64\n",
      " 60  Unfractionated heparin                 943 non-null    float64\n",
      " 61  Vitamin K antagonist                   943 non-null    float64\n",
      " 62  hosp_time_hour                         2039 non-null   int64  \n",
      " 63  icu_count_time                         588 non-null    float64\n",
      " 64  icu_total_los_day                      588 non-null    float64\n",
      " 65  icu_total_hour                         588 non-null    float64\n",
      " 66  re_inhosp_rehosp                       2039 non-null   int64  \n",
      " 67  re_inhosp_time                         70 non-null     float64\n",
      " 68  next_admission_type                    2039 non-null   object \n",
      " 69  death_in1st_hadm                       2039 non-null   int64  \n",
      " 70  death_by_PE                            2039 non-null   int64  \n",
      " 71  seq_num                                175 non-null    float64\n",
      " 72  hospital_expire_flag_death             175 non-null    float64\n",
      " 73  seq_hosp                               2039 non-null   int64  \n",
      " 74  next_PE                                2039 non-null   int64  \n",
      " 75  next_PE_day                            2039 non-null   float64\n",
      "dtypes: bool(23), float64(21), int64(17), object(15)\n",
      "memory usage: 890.2+ KB\n",
      "None\n",
      "death_due_toPE\n",
      "0    2099\n",
      "1      72\n",
      "Name: count, dtype: int64\n",
      "death_in1st_hosp\n",
      "0    2105\n",
      "1      66\n",
      "Name: count, dtype: int64\n",
      "处理后 death_due_toPE\n",
      "1    72\n",
      "Name: count, dtype: int64\n",
      "处理后 death_in1st_hosp\n",
      "1    66\n",
      "0     6\n",
      "Name: count, dtype: int64\n",
      "588\n",
      "588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZhouNan\\AppData\\Local\\Temp\\ipykernel_19436\\2686966121.py:357: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  death_hadm_1 = death_hadm.groupby('subject_id').apply(lambda group: group[(group['death_due_toPE'] != 0) | (group['death_in1st_hosp'] != 0)])\n",
      "C:\\Users\\ZhouNan\\AppData\\Local\\Temp\\ipykernel_19436\\2686966121.py:366: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_data['death_due_toPE'].fillna(0, inplace=True)\n",
      "C:\\Users\\ZhouNan\\AppData\\Local\\Temp\\ipykernel_19436\\2686966121.py:367: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_data['death_in1st_hosp'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b607b8c24ba7308f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
